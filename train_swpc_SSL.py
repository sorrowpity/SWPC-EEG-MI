import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, random_split
import numpy as np
import os
import torch.nn.functional as F
import copy
from scipy.linalg import inv, sqrtm

# å°å…¥è‡ªå®šç¾©æ¨¡å¡Š
from model import EEGNet
from ShallowConvNet_SSL import ShallowConvNet
from EEG_cross_subject_loader_MI_resting import EEG_loader_resting
from EEG_cross_subject_loader_MI import EEG_loader
from visualizer import plot_training_history

# =================================================================
# I. é…ç½®åƒæ•¸ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šæ›´ä½SSLå­¦ä¹ ç‡+æ›´çŸ­SSLè½®æ•°ï¼‰
# =================================================================
BATCH_SIZE = 16
EPOCHS = 500
LR = 0.0005
WEIGHT_DECAY = 0.01
DROPOUT_RATE = 0.6
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
TEST_SUBJ = 1
# æ ¸å¿ƒä¿®å¤1ï¼šé¢„ç­›é€‰SSLå­¦ä¹ ç‡å†é™ä¸€åŠï¼Œé¿å…è¦†ç›–RESTç‰¹å¾
SSL_PRESCREEN_LR = 5e-6    # ä»1e-5 â†’ 5e-6
SSL_CLASSIFIER_LR = 8e-6
SSL_EPOCHS = 20            # æ ¸å¿ƒä¿®å¤2ï¼šSSLè½®æ•°ä»40â†’20ï¼Œå‡å°‘è¿‡åº¦æ‹Ÿåˆ
DELTA = 0.3
SIGMA = 2.0
REST_WEIGHT = 1.5          # RESTæ ·æœ¬æƒé‡ï¼Œå¼ºåˆ¶ä¿ç•™RESTç‰¹å¾

# =================================================================
# II. æ•¸æ“šå¢å¼· + æŸå¤±å‡½æ•°ï¼ˆé›†æˆç»´åº¦åŒ¹é…+RESTæƒé‡ï¼‰
# =================================================================
def augment_batch(inputs, shift_limit=25, noise_level=0.01):
    b, c, h, w = inputs.shape
    for i in range(b):
        shift = np.random.randint(-shift_limit, shift_limit)
        if shift > 0:
            inputs[i, :, :, shift:] = inputs[i, :, :, :-shift]
            inputs[i, :, :, :shift] = 0
        elif shift < 0:
            inputs[i, :, :, :shift] = inputs[i, :, :, -shift:]
            inputs[i, :, :, shift:] = 0
    noise = torch.randn_like(inputs) * noise_level
    return inputs + noise

def create_negative_samples(rest_data, mi_data, n_samples):
    neg_samples = []
    n_rest = len(rest_data)
    n_mi = len(mi_data)
    for _ in range(n_samples):
        r_idx = np.random.randint(0, n_rest)
        m_idx = np.random.randint(0, n_mi)
        r = rest_data[r_idx]
        m = mi_data[m_idx]
        neg = 0.5 * (r + m)
        neg_samples.append(neg)
    return np.array(neg_samples)

# EMAæå–å™¨ï¼ˆä¿æŒæ¢¯åº¦å¯ç”¨ï¼‰
class EMAExtractor:
    def __init__(self, model, decay=0.9995):
        self.model = model
        self.decay = decay
        self.ema_params = None
        self.model.train()
        for param in self.model.parameters():
            param.requires_grad = True
        self.model = self.model.to(DEVICE)

    def update(self):
        if self.ema_params is None:
            self.ema_params = copy.deepcopy(self.model.state_dict())
            print(f"âœ… EMAå‚æ•°åˆå§‹åŒ–å®Œæˆï¼Œå…±{len(self.ema_params)}ä¸ªå‚æ•°")
            return
        current_params = self.model.state_dict()
        for k in self.ema_params.keys():
            assert k in current_params, f"å‚æ•°åä¸åŒ¹é…ï¼š{k}"
            assert self.ema_params[k].shape == current_params[k].shape, f"ç»´åº¦ä¸åŒ¹é…ï¼š{k}"
            self.ema_params[k].data = self.decay * self.ema_params[k].data + (1 - self.decay) * current_params[k].data
        self.model.load_state_dict(self.ema_params)

# é¢„ç­›é€‰æŸå¤±å‡½æ•°ï¼šåŠ å…¥RESTæƒé‡ï¼Œé¿å…é—å¿˜REST
def contrastive_loss(f_theta_pos, f_phi_pos, f_phi_neg):
    f_theta_pos = F.normalize(f_theta_pos, p=2, dim=1)
    f_phi_pos = F.normalize(f_phi_pos, p=2, dim=1)
    f_phi_neg = F.normalize(f_phi_neg, p=2, dim=1)
    pos_dist = torch.sum((f_theta_pos - f_phi_pos) ** 2, dim=1) / (2 * SIGMA ** 2)
    neg_dist = torch.sum((f_theta_pos - f_phi_neg) ** 2, dim=1) / (2 * SIGMA ** 2)
    # æ ¸å¿ƒï¼šç»™è´Ÿæ ·æœ¬ï¼ˆå«RESTï¼‰åŠ æƒé‡ï¼Œå¼ºåˆ¶æ¨¡å‹è®°ä½REST
    loss = -torch.log(torch.exp(-pos_dist) / (torch.exp(-pos_dist) + DELTA * REST_WEIGHT * torch.exp(-neg_dist)))
    return loss.mean()

# åˆ†ç±»æ¨¡å—å¢å¼º+æŸå¤±ï¼ˆä¿æŒä¸å˜ï¼‰
def classifier_augment(x):
    batch_size, _, ch, time = x.shape
    x1 = x.clone()
    x2 = x.clone()
    noise1 = torch.randn_like(x1) * 0.01
    noise2 = torch.randn_like(x2) * 0.01
    x1 += noise1
    x2 += noise2
    scale1 = torch.randint(0, 2, (batch_size, 1, 1, 1), device=x.device) * 0.5 + 0.75
    scale2 = torch.randint(0, 2, (batch_size, 1, 1, 1), device=x.device) * 0.5 + 0.75
    x1 *= scale1
    x2 *= scale2
    mask_prob = 0.5
    mask_len = int(time * 0.05)
    for i in range(batch_size):
        if torch.rand(1) < mask_prob:
            start = torch.randint(0, time - mask_len, (1,)).item()
            x1[i, :, :, start:start+mask_len] = 0
        if torch.rand(1) < mask_prob:
            start = torch.randint(0, time - mask_len, (1,)).item()
            x2[i, :, :, start:start+mask_len] = 0
    shift1 = np.random.randint(-10, 10, batch_size)
    shift2 = np.random.randint(-10, 10, batch_size)
    for i in range(batch_size):
        x1[i] = torch.roll(x1[i], shift1[i], dims=-1)
        x2[i] = torch.roll(x2[i], shift2[i], dims=-1)
    return x1, x2

def classifier_contrastive_loss(f_theta, f_phi):
    f_theta = F.normalize(f_theta, p=2, dim=1)
    f_phi = F.normalize(f_phi, p=2, dim=1)
    batch_size = f_theta.shape[0]
    pos_dist = torch.sum((f_theta - f_phi) ** 2, dim=1) / (2 * SIGMA ** 2)
    neg_dist = []
    for i in range(batch_size):
        neg_mask = torch.arange(batch_size) != i
        neg_phi = f_phi[neg_mask]
        i_dist = torch.sum((f_theta[i].unsqueeze(0) - neg_phi) ** 2, dim=1) / (2 * SIGMA ** 2)
        neg_dist.append(i_dist.min())
    neg_dist = torch.stack(neg_dist)
    loss = -torch.log(torch.exp(-pos_dist) / (torch.exp(-pos_dist) + DELTA * torch.exp(-neg_dist)))
    return loss.mean()

# =================================================================
# III. EAç‰¹å¾å¯¹é½ï¼ˆä¿æŒä¸å˜ï¼‰
# =================================================================
def compute_EA_matrix(X):
    n_samples, n_channels = X.shape[0], X.shape[1]
    cov = np.zeros((n_channels, n_channels))
    for i in range(n_samples):
        trial_cov = np.dot(X[i], X[i].T) / X.shape[2]
        cov += trial_cov
    mean_cov = cov / n_samples
    R = inv(sqrtm(mean_cov)).real
    return R

def apply_EA_to_dataset(X, subj_indices):
    X_aligned = np.zeros_like(X)
    unique_subjs = np.unique(subj_indices)
    print(f"--- æ‰§è¡ŒEAå¯¹é½ï¼Œå…±{len(unique_subjs)}ä¸ªè¢«è¯•ï¼Œé€šé“æ•°{X.shape[1]} ---")
    for subj in unique_subjs:
        mask = (subj_indices == subj)
        R = compute_EA_matrix(X[mask])
        X_aligned[mask] = np.matmul(R, X[mask])
    return X_aligned

# =================================================================
# IV. æ ¸å¿ƒè¨“ç·´æµç¨‹ï¼ˆé›†æˆç»´åº¦åŒ¹é…+æ··åˆç›‘ç£æŸå¤±ï¼‰
# =================================================================
def train_process(model, train_loader, val_loader, criterion, optimizer, save_path,
                  is_prescreen=False, rest_data=None, mi_data=None, is_classifier=False):
    best_val_loss = float('inf')
    patience = 30
    counter = 0
    history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5)
    print(f"\nğŸ“Œ å¼€å§‹è®­ç»ƒ: {save_path} | è®¾å¤‡: {DEVICE} | æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")

    # ç¬¬ä¸€éšæ®µï¼šç›£ç£è¨“ç·´ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    for epoch in range(EPOCHS):
        model.train()
        t_loss, t_correct, t_total = 0, 0, 0
        for inputs, labels in train_loader:
            inputs = (inputs - inputs.mean(dim=-1, keepdim=True)) / (inputs.std(dim=-1, keepdim=True) + 1e-6)
            inputs = inputs.unsqueeze(1).float().to(DEVICE)
            if not is_prescreen:
                inputs = augment_batch(inputs, shift_limit=30, noise_level=0.02)
            labels = labels.long().to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)
            optimizer.step()

            t_loss += loss.item()
            _, pred = torch.max(outputs, 1)
            t_total += labels.size(0)
            t_correct += (pred == labels).sum().item()

        model.eval()
        v_loss, v_correct, v_total = 0, 0, 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs = (inputs - inputs.mean(dim=-1, keepdim=True)) / (inputs.std(dim=-1, keepdim=True) + 1e-6)
                inputs = inputs.unsqueeze(1).float().to(DEVICE)
                labels = labels.long().to(DEVICE)
                outputs = model(inputs)
                v_loss += criterion(outputs, labels).item()
                _, pred = torch.max(outputs, 1)
                v_total += labels.size(0)
                v_correct += (pred == labels).sum().item()

        epoch_t_acc = 100 * t_correct / t_total
        epoch_v_acc = 100 * v_correct / v_total
        epoch_v_loss = v_loss / len(val_loader)
        scheduler.step(epoch_v_loss)

        history['loss'].append(t_loss / len(train_loader))
        history['acc'].append(epoch_t_acc)
        history['val_loss'].append(epoch_v_loss)
        history['val_acc'].append(epoch_v_acc)

        if epoch_v_loss < best_val_loss:
            best_val_loss = epoch_v_loss
            torch.save(model.state_dict(), save_path)
            counter = 0
        else:
            counter += 1

        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1:03d} | è®­ç»ƒç²¾åº¦: {epoch_t_acc:5.1f}% | éªŒè¯ç²¾åº¦: {epoch_v_acc:5.1f}% | éªŒè¯æŸå¤±: {epoch_v_loss:.4f}")
        if counter >= patience:
            print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨ç¬¬{epoch+1}è½®åœæ­¢ç›‘ç£è®­ç»ƒ")
            break

    # ç¬¬äºŒéšæ®µï¼šSSLå¾®èª¿ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šç»´åº¦åŒ¹é…+æ··åˆç›‘ç£æŸå¤±ï¼‰
    if is_prescreen and rest_data is not None and mi_data is not None:
        print("\n=== å¼€å§‹é¢„ç­›é€‰æ¨¡å— SSL å¾®è°ƒï¼ˆRest/MIï¼‰===")
        n_total_train = len(train_loader.dataset)
        neg_samples = create_negative_samples(rest_data, mi_data, n_total_train)
        print(f"ğŸ“Š è´Ÿæ ·æœ¬ç”Ÿæˆå®Œæˆï¼š{len(neg_samples)}ä¸ªï¼ˆä¸è®­ç»ƒé›†ä¸€è‡´ï¼‰")

        # æå‰åˆå§‹åŒ–æ¨¡å‹ç‰¹å¾æå–
        model.eval()
        with torch.no_grad():
            for inputs, _ in train_loader:
                inputs = (inputs - inputs.mean(dim=-1, keepdim=True)) / (inputs.std(dim=-1, keepdim=True) + 1e-6)
                inputs = inputs.unsqueeze(1).float().to(DEVICE)
                _ = model.extract_feature(inputs)
                break

        # å†»ç»“å·ç§¯å±‚ï¼Œä»…è®­ç»ƒå…¨è¿æ¥å±‚
        params_to_train = []
        for name, param in model.named_parameters():
            if "fc" in name:
                param.requires_grad = True
                params_to_train.append(param)
                print(f"ğŸ”“ è§£é”SSLè®­ç»ƒï¼š{name} ({param.shape})")
            else:
                param.requires_grad = False
                print(f"ğŸ”’ å†»ç»“SSLè®­ç»ƒï¼š{name} ({param.shape})")

        ema_extractor = EMAExtractor(model)
        ssl_optimizer = optim.Adam(params_to_train, lr=SSL_PRESCREEN_LR, weight_decay=WEIGHT_DECAY)

        # SSLå¾®è°ƒè®­ç»ƒï¼ˆæ ¸å¿ƒä¿®å¤ï¼šç»´åº¦åŒ¹é…+æ··åˆç›‘ç£æŸå¤±ï¼‰
        for ssl_epoch in range(SSL_EPOCHS):
            model.train()
            ssl_total_loss = 0.0
            for batch_idx, (inputs, labels) in enumerate(train_loader):  # å…³é”®ï¼šåŒæ—¶è·å–labels
                # æ ¸å¿ƒä¿®å¤3ï¼šåŠ¨æ€è·å–å½“å‰æ‰¹æ¬¡å®é™…å¤§å°ï¼Œé¿å…ç»´åº¦ä¸åŒ¹é…
                batch_size = inputs.shape[0]
                inputs = (inputs - inputs.mean(dim=-1, keepdim=True)) / (inputs.std(dim=-1, keepdim=True) + 1e-6)
                inputs = inputs.unsqueeze(1).float().to(DEVICE)
                labels = labels.long().to(DEVICE)  # æ ‡ç­¾ä¹Ÿç§»åˆ°è®¾å¤‡

                # æ ¸å¿ƒä¿®å¤4ï¼šæŒ‰å®é™…æ‰¹æ¬¡å¤§å°æˆªå–è´Ÿæ ·æœ¬ï¼Œä¿è¯ç»´åº¦ä¸€è‡´
                start_idx = batch_idx * BATCH_SIZE
                end_idx = start_idx + batch_size
                neg_batch = neg_samples[start_idx:end_idx]
                # å…œåº•ï¼šå¦‚æœè´Ÿæ ·æœ¬ä¸å¤Ÿï¼Œé‡å¤å¡«å……ï¼ˆé¿å…ç»´åº¦é”™è¯¯ï¼‰
                if len(neg_batch) < batch_size:
                    neg_batch = np.pad(neg_batch, ((0, batch_size - len(neg_batch)), (0,0), (0,0)), mode='wrap')
                neg_inputs = torch.from_numpy(neg_batch).unsqueeze(1).float().to(DEVICE)

                # å¼ºåˆ¶å¯ç”¨æ¢¯åº¦
                with torch.enable_grad():
                    f_theta_pos = model.extract_feature(inputs)
                    f_phi_pos = ema_extractor.model.extract_feature(inputs)
                    f_phi_neg = ema_extractor.model.extract_feature(neg_inputs)

                # æ ¸å¿ƒä¿®å¤5ï¼šæ··åˆSSLæŸå¤±+ç›‘ç£æŸå¤±ï¼ˆ9:1ï¼‰ï¼Œä¿ç•™Rest/MIåˆ†ç±»èƒ½åŠ›
                ssl_loss = contrastive_loss(f_theta_pos, f_phi_pos, f_phi_neg)
                supervise_output = model(inputs)
                supervise_loss = criterion(supervise_output, labels)
                # 90% SSLæŸå¤± + 10% ç›‘ç£æŸå¤±ï¼Œé¿å…é—å¿˜REST
                total_loss = 0.9 * ssl_loss + 0.1 * supervise_loss

                ssl_optimizer.zero_grad()
                total_loss.backward()
                ssl_optimizer.step()
                ema_extractor.update()

                ssl_total_loss += total_loss.item()

            # æ‰“å°SSLæ—¥å¿—
            avg_loss = ssl_total_loss / len(train_loader)
            if (ssl_epoch + 1) % 5 == 0:  # æ¯5è½®æ‰“å°ä¸€æ¬¡
                print(f"SSL Epoch {ssl_epoch+1}/{SSL_EPOCHS} | æ··åˆæŸå¤±: {avg_loss:.4f}")

        # ä¿å­˜SSLæ¨¡å‹
        ssl_save_path = save_path.replace('.pth', '_ssl.pth')
        torch.save(model.state_dict(), ssl_save_path)
        print(f"âœ… é¢„ç­›é€‰æ¨¡å—SSLå®Œæˆ | æ¨¡å‹ä¿å­˜è‡³: {ssl_save_path}")

    elif is_classifier:
        print("\n=== å¼€å§‹åˆ†ç±»æ¨¡å— SSL å¾®è°ƒï¼ˆLeft/Rightï¼‰===")
        params_to_train = []
        for name, param in model.named_parameters():
            if "fc" in name or "classifier" in name:
                param.requires_grad = True
                params_to_train.append(param)
                print(f"ğŸ”“ è§£é”SSLè®­ç»ƒï¼š{name} ({param.shape})")
            else:
                param.requires_grad = False
                print(f"ğŸ”’ å†»ç»“SSLè®­ç»ƒï¼š{name} ({param.shape})")

        ema_extractor = EMAExtractor(model)
        ssl_optimizer = optim.Adam(params_to_train, lr=SSL_CLASSIFIER_LR, weight_decay=WEIGHT_DECAY)

        for ssl_epoch in range(SSL_EPOCHS):
            model.train()
            ssl_total_loss = 0.0
            for inputs, _ in train_loader:
                inputs = (inputs - inputs.mean(dim=-1, keepdim=True)) / (inputs.std(dim=-1, keepdim=True) + 1e-6)
                inputs = inputs.unsqueeze(1).float().to(DEVICE)
                x1, x2 = classifier_augment(inputs)

                with torch.enable_grad():
                    f_theta = model.extract_feature(x1)
                    f_phi = ema_extractor.model.extract_feature(x2)

                ssl_loss = classifier_contrastive_loss(f_theta, f_phi)
                ssl_optimizer.zero_grad()
                ssl_loss.backward()
                ssl_optimizer.step()
                ema_extractor.update()

                ssl_total_loss += ssl_loss.item()

            avg_loss = ssl_total_loss / len(train_loader)
            if (ssl_epoch + 1) % 5 == 0:
                print(f"SSL Epoch {ssl_epoch+1}/{SSL_EPOCHS} | å¯¹æ¯”æŸå¤±: {avg_loss:.4f}")

        ssl_save_path = save_path.replace('.pth', '_ssl.pth')
        torch.save(model.state_dict(), ssl_save_path)
        print(f"âœ… åˆ†ç±»æ¨¡å—SSLå®Œæˆ | æ¨¡å‹ä¿å­˜è‡³: {ssl_save_path}")

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_training_history(history, title=os.path.basename(save_path), save_path=f"{save_path}.png")
    print(f"\nğŸ“¦ è®­ç»ƒæµç¨‹ç»“æŸ | æœ€ä½³ç›‘ç£æ¨¡å‹: {save_path} | SSLæ¨¡å‹: {ssl_save_path if (is_prescreen or is_classifier) else 'æ— '}\n")

# =================================================================
# V. ä¸»å‡½æ•¸ï¼ˆä¿æŒä¸å˜ï¼‰
# =================================================================
def main():
    # Stage 1: é¢„ç­›é€‰æ¨¡å—è®­ç»ƒ
    print(">>> [Stage 1] è®­ç»ƒé¢„ç­›é€‰æ¨¡å‹ï¼ˆShallowConvNet: Rest vs MIï¼‰")
    loader_rest = EEG_loader_resting(test_subj=TEST_SUBJ)
    n_channels = int(loader_rest.train_x.shape[1])
    n_timepoints = int(loader_rest.train_x.shape[2])
    print(f"ğŸ“¥ é¢„ç­›é€‰æ¨¡å—è¾“å…¥ç»´åº¦ï¼š{n_channels}é€šé“ Ã— {n_timepoints}æ—¶é—´ç‚¹")

    train_x_ea = apply_EA_to_dataset(loader_rest.train_x, loader_rest.train_subj)
    rest_data = loader_rest.train_x[loader_rest.train_y == 0]
    mi_data = loader_rest.train_x[loader_rest.train_y == 1]
    print(f"ğŸ“Š é¢„ç­›é€‰è®­ç»ƒæ•°æ®ï¼šRest{len(rest_data)}ä¸ª | MI{len(mi_data)}ä¸ª")

    full_ds_1 = TensorDataset(torch.from_numpy(train_x_ea), torch.from_numpy(loader_rest.train_y))
    train_size = int(0.8 * len(full_ds_1))
    val_size = len(full_ds_1) - train_size
    ds_train_1, ds_val_1 = random_split(full_ds_1, [train_size, val_size])
    train_loader_1 = DataLoader(ds_train_1, batch_size=BATCH_SIZE, shuffle=True)
    val_loader_1 = DataLoader(ds_val_1, batch_size=BATCH_SIZE)

    model_1 = ShallowConvNet(
        num_classes=2,
        channels=n_channels,
        time_points=n_timepoints,
        dropout_rate=DROPOUT_RATE
    ).to(DEVICE)
    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)
    optimizer_1 = optim.Adam(model_1.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

    train_process(
        model=model_1,
        train_loader=train_loader_1,
        val_loader=val_loader_1,
        criterion=criterion,
        optimizer=optimizer_1,
        save_path='prescreen_model.pth',
        is_prescreen=True,
        rest_data=rest_data,
        mi_data=mi_data
    )

    # Stage 2: åˆ†ç±»æ¨¡å—è®­ç»ƒ
    print(">>> [Stage 2] è®­ç»ƒåˆ†ç±»æ¨¡å‹ï¼ˆEEGNet: Left vs Rightï¼‰")
    loader_cls = EEG_loader(test_subj=TEST_SUBJ)
    print(f"åŸå§‹åˆ†ç±»æ ‡ç­¾ï¼š{np.unique(loader_cls.train_y)}")
    loader_cls.train_y = np.where(loader_cls.train_y == 1, 0, 1)
    valid_mask = (loader_cls.train_y == 0) | (loader_cls.train_y == 1)
    loader_cls.train_x = loader_cls.train_x[valid_mask]
    loader_cls.train_y = loader_cls.train_y[valid_mask]
    print(f"å½’ä¸€åŒ–åæ ‡ç­¾ï¼š{np.unique(loader_cls.train_y)} | æœ‰æ•ˆæ ·æœ¬ï¼š{len(loader_cls.train_x)}")
    print(f"ç±»åˆ«åˆ†å¸ƒï¼šLeft(0){sum(loader_cls.train_y==0)}ä¸ª | Right(1){sum(loader_cls.train_y==1)}ä¸ª")

    n_channels_cls = int(loader_cls.train_x.shape[1])
    n_timepoints_cls = int(loader_cls.train_x.shape[2])
    print(f"ğŸ“¥ åˆ†ç±»æ¨¡å—è¾“å…¥ç»´åº¦ï¼š{n_channels_cls}é€šé“ Ã— {n_timepoints_cls}æ—¶é—´ç‚¹")

    if hasattr(loader_cls, 'train_subj'):
        train_x_ea_2 = apply_EA_to_dataset(loader_cls.train_x, loader_cls.train_subj)
    else:
        print("âš ï¸ è­¦å‘Šï¼šåˆ†ç±»æ¨¡å—æ— è¢«è¯•ç´¢å¼•ï¼Œä½¿ç”¨å…¨å±€EAå¯¹é½")
        R_global = compute_EA_matrix(loader_cls.train_x)
        train_x_ea_2 = np.matmul(R_global, loader_cls.train_x)

    full_ds_2 = TensorDataset(
        torch.from_numpy(train_x_ea_2),
        torch.from_numpy(loader_cls.train_y).long()
    )
    train_size_2 = int(0.8 * len(full_ds_2))
    val_size_2 = len(full_ds_2) - train_size_2
    ds_train_2, ds_val_2 = random_split(full_ds_2, [train_size_2, val_size_2])
    train_loader_2 = DataLoader(ds_train_2, batch_size=BATCH_SIZE, shuffle=True)
    val_loader_2 = DataLoader(ds_val_2, batch_size=BATCH_SIZE)

    model_2 = EEGNet(
        num_classes=2,
        channels=n_channels_cls,
        time_points=n_timepoints_cls,
        dropout_rate=DROPOUT_RATE
    ).to(DEVICE)
    criterion_cls = nn.CrossEntropyLoss()
    optimizer_2 = optim.Adam(model_2.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

    train_process(
        model=model_2,
        train_loader=train_loader_2,
        val_loader=val_loader_2,
        criterion=criterion_cls,
        optimizer=optimizer_2,
        save_path='classifier_model.pth',
        is_classifier=True
    )

    print(">>> ğŸ”¥ æ‰€æœ‰è®­ç»ƒå®Œæˆï¼ç”Ÿæˆæ¨¡å‹ï¼šprescreen_model_ssl.pth | classifier_model_ssl.pth")

if __name__ == '__main__':
    main()